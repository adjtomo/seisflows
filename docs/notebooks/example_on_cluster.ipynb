{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Examples on a Cluster\n",
    "\n",
    "Here we detail how a User might transition from developing a 2D example problem on their workstation, to performing large-scale inversion on a cluster. In this notebook we show an example running on the New Zealand eScience Infrastructure HPC, named Maui, but is meant to provide a generalizable approach for running SeisFlows on clusters. \n",
    "\n",
    "## Example Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We first set up our working directory using the example setup shown in the `SPECFEM2D example page <specfem2d_example.html>`__. This ensures that we have our initial and final models, and a properly set parameter file that can be used for our inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bchow/Work/scratch\n"
     ]
    }
   ],
   "source": [
    "# This is an empty working directory\n",
    "%cd /home/bchow/Work/scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ln -s /home/bchow/REPOSITORIES/specfem2d .  # place SPECFEM2D repository in the working directory\n",
    "! seisflows examples setup 2  # run example setup but do not `submit` workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters.yaml  specfem2d  specfem2d_workdir\r\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 'swap'\n",
    "\n",
    "As we saw in the example tutorial, the `System` module for this example problem is set as 'Workstation', which is meant to run the workflow in serial directly on the system that submits it. For clusters this means we would run our entire inversion on the login node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: workstation\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows par system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To 'swap' out the `System` module for a cluster-specific class, we can use the `seisflows swap` command, which replaces one module for another without affecting the other modules. This is very helpful if you have a completed parameter file and do not want to copy-paste all the edited parameter just to change out a module. The rubric for running `seisflows swap` can be found in the help message:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: seisflows swap [-h] [module] [classname]\r\n",
      "\r\n",
      "During workflow development, it may be necessary to swap between different\r\n",
      "sub-modules (e.g., system.workstation -> system.cluster). However this would\r\n",
      "typically involving re-generating and re-filling a parameter file. The 'swap'\r\n",
      "function makes it easier to swap parameters between modules.\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  module      Module name to swap\r\n",
      "  classname   Classname to swap to\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help  show this help message and exit\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows swap -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check available names by running `seisflows print modules`. Here we want to swap out our `System` module from 'Workstation' to 'Maui', which defines how SeisFlows interacts with the SLURM-based system, Maui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SEISFLOWS MODULES                                \r\n",
      "                               /////////////////                                \r\n",
      "'-': module, '*': class\r\n",
      "\r\n",
      "- workflow\r\n",
      "    * forward\r\n",
      "    * inversion\r\n",
      "    * migration\r\n",
      "    * test_flow\r\n",
      "- system\r\n",
      "    * chinook\r\n",
      "    * cluster\r\n",
      "    * frontera\r\n",
      "    * lsf\r\n",
      "    * maui\r\n",
      "    * slurm\r\n",
      "    * workstation\r\n",
      "- solver\r\n",
      "    * specfem\r\n",
      "    * specfem2d\r\n",
      "    * specfem3d\r\n",
      "    * specfem3d_globe\r\n",
      "- preprocess\r\n",
      "    * default\r\n",
      "    * pyaflowa\r\n",
      "- optimize\r\n",
      "    * LBFGS\r\n",
      "    * NLCG\r\n",
      "    * gradient\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows print modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-BFGS optimization requires 'backtrack'ing line search. Overwriting 'bracket'\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows swap system maui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the parameter file has swapped out the 'Workstation' System module for the 'Maui' System module, which contains its own set of parameters that must be filled out by the User."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# =============================================================================\r\n",
      "#\r\n",
      "#    Workstation System\r\n",
      "#    ------------------\r\n",
      "#    Defines foundational structure for System module. When used standalone, \r\n",
      "#    runs tasks in serial on a local machine.\r\n",
      "#\r\n",
      "#    Parameters\r\n",
      "#    ----------\r\n",
      "#    :type ntask: int\r\n",
      "#    :param ntask: number of individual tasks/events to run during workflow.\r\n",
      "#        Must be <= the number of source files in `path_specfem_data`\r\n",
      "#    :type nproc: int\r\n",
      "#    :param nproc: number of processors to use for each simulation\r\n",
      "#    :type log_level: str\r\n",
      "#    :param log_level: logger level to pass to logging module.\r\n",
      "#        Available: 'debug', 'info', 'warning', 'critical'\r\n",
      "#    :type verbose: bool\r\n",
      "#    :param verbose: if True, formats the log messages to include the file\r\n",
      "#        name, line number and message type. Useful for debugging but\r\n",
      "#        also very verbose.\r\n",
      "#\r\n",
      "#        \r\n",
      "#    Cluster System\r\n",
      "#    ------------------\r\n",
      "#    Generic or common HPC/cluster interfacing commands\r\n",
      "#\r\n",
      "#    Parameters\r\n",
      "#    ----------\r\n",
      "#    :type title: str\r\n",
      "#    :param title: The name used to submit jobs to the system, defaults\r\n",
      "#        to the name of the current working directory\r\n",
      "#    :type mpiexec: str\r\n",
      "#    :param mpiexec: Function used to invoke executables on the system.\r\n",
      "#        For example 'mpirun', 'mpiexec', 'srun', 'ibrun'\r\n",
      "#    :type ntask_max: int\r\n",
      "#    :param ntask_max: limit the number of concurrent tasks in a given array job\r\n",
      "#    :type walltime: float\r\n",
      "#    :param walltime: maximum job time in minutes for the master SeisFlows\r\n",
      "#        job submitted to cluster. Fractions of minutes acceptable.\r\n",
      "#    :type tasktime: float\r\n",
      "#    :param tasktime: maximum job time in minutes for each job spawned by\r\n",
      "#        the SeisFlows master job during a workflow. These include, e.g.,\r\n",
      "#        running the forward solver, adjoint solver, smoother, kernel combiner.\r\n",
      "#        All spawned tasks receive the same task time. Fractions of minutes\r\n",
      "#        acceptable.\r\n",
      "#    :type environs: str\r\n",
      "#    :param environs: Optional environment variables to be provided in the\r\n",
      "#        following format VAR1=var1,VAR2=var2... Will be set using\r\n",
      "#        os.environs\r\n",
      "#\r\n",
      "#        \r\n",
      "#    System Slurm\r\n",
      "#    ------------------\r\n",
      "#    Interface for submitting and monitoring jobs on HPC systems running the \r\n",
      "#    Simple Linux Utility for Resource Management (SLURM) workload manager.\r\n",
      "#\r\n",
      "#    Parameters\r\n",
      "#    ----------\r\n",
      "#    :type slurm_args: str\r\n",
      "#    :param slurm_args: Any (optional) additional SLURM arguments that will\r\n",
      "#        be passed to the SBATCH scripts. Should be in the form:\r\n",
      "#        '--key1=value1 --key2=value2\"\r\n",
      "#\r\n",
      "#        \r\n",
      "#    System Maui\r\n",
      "#    -----------\r\n",
      "#    New Zealand Maui-specfic modifications to base SLURM system\r\n",
      "#\r\n",
      "#    Parameters\r\n",
      "#    ----------\r\n",
      "#    :type account: str\r\n",
      "#    :param account: Maui account to submit jobs under, will be used for the\r\n",
      "#        '--account' sbatch argument\r\n",
      "#    :type cpus_per_task: int\r\n",
      "#    :param cpus_per_task: allow for multiple cpus per task, i.e,.\r\n",
      "#        multithreaded jobs\r\n",
      "#    :type cluster: str\r\n",
      "#    :param cluster: cluster to submit jobs to. Available are Maui and\r\n",
      "#        Mahuika\r\n",
      "#    :type partition: str\r\n",
      "#    :param partition: partition of the cluster to submit jobs to.\r\n",
      "#    :type ancil_cluster: str\r\n",
      "#    :param ancil_cluster: name of the ancilary cluster used for pre-\r\n",
      "#        post-processing tasks.\r\n",
      "#    :type ancil_partition: name of the partition of the ancilary cluster\r\n",
      "#    :type ancil_tasktime: int\r\n",
      "#    :param ancil_tasktime: Tasktime in minutes for pre and post-processing\r\n",
      "#        jobs submitted to Maui ancil.\r\n",
      "#\r\n",
      "#        \r\n",
      "# =============================================================================\r\n",
      "ntask: 1\r\n",
      "nproc: 1\r\n",
      "log_level: DEBUG\r\n",
      "verbose: False\r\n",
      "title: scratch\r\n",
      "mpiexec:  None\r\n",
      "ntask_max: 100\r\n",
      "walltime: 10\r\n",
      "tasktime: 1\r\n",
      "environs: SLURM_MEM_PER_CPU\r\n",
      "slurm_args:  None\r\n",
      "partition: nesi_research\r\n",
      "account: None\r\n",
      "cluster: maui\r\n",
      "cpus_per_task: 1\r\n",
      "ancil_cluster: maui_ancil\r\n",
      "ancil_partition: nesi_prepost\r\n",
      "ancil_tasktime: 1\r\n"
     ]
    }
   ],
   "source": [
    "! head -235 parameters.yaml | tail -n 110 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Check'ing parameter validity\n",
    "\n",
    "Most of the default values should be okay for our purposes, but it's up the User to read the docstrings and determine if any of the default values should be changed. If we run `seisflows check` we can check if any of our parameters are incorrectly set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "================================================================================\r\n",
      "                                PARAMETER ERRROR                                \r\n",
      "                                ////////////////                                \r\n",
      "System 'Maui' requires parameter 'account'\r\n",
      "================================================================================\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Maui` System check function has told us that it requires that the parameter `account` be set. Note that these requirements will change between different clusters, which dictate different SLURM parameters when submitting jobs. We can specify the account parameter using the `seisflows par` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account: null -> gns03247\r\n"
     ]
    }
   ],
   "source": [
    "! seisflows par account gns03247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `seisflows check` function has passed and we have succesfully swapped out our System module with the `Maui` child class. Under the hood, this class should take care of all the required interactions between SeisFlows and the compute node. Now all that is left to do is to run `seisflows submit`, which should submit the master job to the system and run our inversion on compute nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestFlow: Live testing SeisFlows on System\n",
    "\n",
    "While developing, debugging or testing SeisFlows on System, it is not ideal to submit simulation-based workflows, as these eat large amounts of computational resources and may introduce problems of there own. \n",
    "\n",
    "Here we introduce 'TestFlow', a SeisFlows workflow that runs simple test functions on a cluster. This allows Users to check if SeisFlows can appropriately interact with the HPC system with tasks like submitting jobs, monitoring the job queue and catching failing jobs. \n",
    "\n",
    "Below we show how to set up TestFlow for our test bed HPC, Maui. First we generate a template parameter file and set the modules appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "/home/bchow/Work/scratch\n"
     ]
    }
   ],
   "source": [
    "# This is an empty working directory\n",
    "%rm -r /home/bchow/Work/scratch \n",
    "%mkdir /home/bchow/Work/scratch \n",
    "%cd /home/bchow/Work/scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating parameter file: parameters.yaml\r\n"
     ]
    }
   ],
   "source": [
    "# Generate a template parameter file\n",
    "! seisflows setup -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow: forward -> test_flow\n",
      "system: workstation -> maui\n",
      "solver: specfem2d -> null\n",
      "preprocess: default -> null\n",
      "optimize: gradient -> null\n"
     ]
    }
   ],
   "source": [
    "# Set the modules appropriately\n",
    "! seisflows par workflow test_flow\n",
    "! seisflows par system maui  # we want to test SeisFlows on Maui\n",
    "! seisflows par solver null  # currently test_flow does not test solver\n",
    "! seisflows par preprocess null  # currently test_flow does not test preprocess\n",
    "! seisflows par optimize null  # currently test_flow does not test optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically fill out the parameter file\n",
    "! seisflows configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# =============================================================================\r\n",
      "#\r\n",
      "#    TestFlow Workflow\r\n",
      "#    -------------\r\n",
      "#    Test individual sub-modules in a 'live' testing environment in order to\r\n",
      "#    ensure SeisFlows works appropriately given an established system and solver.\r\n",
      "#\r\n",
      "#    .. note::\r\n",
      "#        You do not need to set System parameters `ntask`, `nproc`, `tasktime`,\r\n",
      "#        `walltime`. These will be overwritten by the setup task.\r\n",
      "#\r\n",
      "#    Parameters\r\n",
      "#    ----------\r\n",
      "#\r\n",
      "#        \r\n",
      "# =============================================================================\r\n"
     ]
    }
   ],
   "source": [
    "! head -48 parameters.yaml | tail -n 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the `TestFlow` workflow does not require any input parameters, and will additionally automatically set some key `System` parameters to ensure that these tests are lightweight to avoid long queue times. Under the hood the `TestFlow` workflow will:\n",
    "\n",
    "1) Submit an array job to the system to test job submission capabilities  \n",
    "2) Submit a single job to the system which is intended to fail, this tests job queue monitoring as well as failed job catching.\n",
    "\n",
    "Developers who are implementing new `System` classes (e.g., for new clusters), can use TestFlow as foundation for their development and debugging sessions. To run the `TestFlow` workflow you just need to run `seisflows submit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
