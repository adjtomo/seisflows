#!/usr/bin/env python3
"""
Ambient Noise Adjoint Tomography workflow based on Wang et al. (see ref. below)
where Synthetic Greens functions (SGF) are generated by simulating point forces
in the Z, N and E directions. SGFs are rotated to the R and T components
to get ZZ, RR and TT SGFs that can be compared to data.

.. note:: EGF Data Location

    Empirical Greens Function data (noise cross correlations) must be placed
    in specific directory structures, and are searched for under the following
    locations:

        ZZ kernel: `path_data`/{source_name}/ZZ/*
        RR kernel: `path_data`/{source_name}/RR/*
        TT kernel: `path_data`/{source_name}/TT/*

.. note:: Kernel Naming

    Naming convention: AB (A=force source direction, B=waveform component)

    The kernel naming convention used in this workflow follows from Ref. 1.
    Two letter names (e.g., AB) where first letter (A) represents input force
    direction, and second letter (B) represents the component of the recorded
    wavefield. E.g., ZZ represents an upward (+Z) force recorded on Z component.
    In ambient noise, the common EGFs are ZZ, TT and RR. Cross-component EGFs
    (e.g., ZT) are also possible, but not currently supported. Please open
    a GitHub issue if you would like to see these supported.

.. note:: TT/RR Workflow Steps:

    FORWARD SIMULATIONS
    1. Run E component forward simulation, save ZNE traces & fwd arrays
    2. Run N component forward simulations, save ZNE traces & fwd arrays
    3. Rotate N and E component SGF to R and T components based on
       source-receiver azimuth
    4. Calculate RR and TT adjoint sources (u_rr, u_tt) w.r.t EGF data

    GENERATE TT KERNELS
    5a. Rotate u_tt to N and E (u_ee, u_en, u_ne, u_nn)
    6a. Run ET adjoint simulation (injecting u_ee, u_en) for K_ET
    7a. Run NT adjoint simulation (injecting u_ne, u_nn) for K_NT
    8a. Sum T kernels, K_ET + K_NT = K_TT

    GENERATE RR KERNELS
    5b. Rotate u_rr to N and E (u_ee, u_en, u_ne, u_nn)
    6b. Run ER adjoint simulation (injecting u_ee, u_en) for K_ER
    7b. Run NR adjoint simulation (injecting u_ne, u_nn) for K_NR
    8b. Sum R kernels, K_ER + K_NR = K_RR

    9. Sum kernels K = K_RR + K_TT

.. note:: References

    1. "Three‐dimensional sensitivity kernels for multicomponent empirical
        Green's functions from ambient noise: Methodology and application to
        Adjoint tomography."
        Journal of Geophysical Research: Solid Earth 124.6 (2019): 5794-5810.

.. warning::

    This workflow class makes a lot of assumptions about file naming and 
    path structure defined in other modules that is verging on hard coding. May
    warrant a re-write in the future.  I've tried to mark all the file/dir.
    naming assumptions with a '!!!'
"""
import os

from concurrent.futures import ProcessPoolExecutor, wait
from glob import glob
from obspy import Stream

from seisflows import logger
from seisflows.tools import unix, msg
from seisflows.tools.noise import rotate_ne_trace_to_rt, rotate_rt_adjsrc_to_ne
from seisflows.tools.specfem import (rename_as_adjoint_source, getpar,
                                     get_src_rcv_lookup_table)
from seisflows.preprocess.default import read, write
from seisflows.workflow.inversion import Inversion


class NoiseInversion(Inversion):
    """
    Noise Inversion Workflow
    ------------------------
    Run forward and adjoint solvers to produce Synthetic Greens Functions (SGF)
    based on unidirectional forces which are meant to represent virtual
    sources of uniform noise distributions. SGFs are compared to Empirical
    Greens Functions (EGF) for iterative model updates.

    .. note:: simulation requirements per source station

        - 'ZZ' kernel requires 1 forward (Z) and 1 adjoint (Z) simulation
        - 'TT or RR' kernel requires 2 forward (N + E) and 2 adjoint (N_? + E_?)
           simulations (where ? = R or T)
        - 'TT,RR' kernels can share their 2 forward simulations (N + E) but
          require 4 separate adjoint simulations (N_T + E_T + N_R + E_R)
        - 'ZZ,TT or ZZ,RR' requires 3 forward (Z + N + E) and 3 adjoint
        - 'ZZ,TT,RR' requires 3 forward (Z + N + E) and 5 adjoint
           (Z + N_T + E_T + N_R + E_R)

    Parameters
    ----------
    :type kernels: str
    :param kernels: comma-separated list of kernels to generate w.r.t available
        EGF data. Corresponding data must be available. Available options are:
        - ZZ: Generates Synthetic Greens Functions (SGF) for the ZZ (vertical)
        component by running forward simulations for each master station using a
        +Z component force, and then running an adjoint simulation to generate
        kernels.
        - TT/RR: Generate Synthetic Greens Functions (SGF) for the TT
        (transvserse) and/or RR (radial) component(s) following processing
        steps laid out in Wang et al. (2019) and outlined below:

        Example inputs would be 'ZZ' or 'ZZ,TT' or 'ZZ,TT,RR'. Case insensitive
    :type separate_rt_kernels: bool
    :param separate_rt_kernels: >>> WORK IN PROGRESS, MUST BE SET TRUE <<<
        if True, generate separate kernels for RR and TT
        which requires 4 adjoint simulations (ER, ET, NR, NT). If False, mix 
        RR and TT kernel generation for computional efficiency, requiring only 
        2 adjoint simulations (ER+NR, ET+NT), but losing the ability to look at 
        RR and TT kernels separately. Default is False with the assumption that 
        the User only cares about the sum and not the individual kernels. 

    Paths
    -----

    ***
    """
    __doc__ = Inversion.__doc__ + __doc__

    def __init__(self, kernels="ZZ", separate_rt_kernels=True,
                 **kwargs):
        """
        Initialization of the Noise Inversion Workflow module
        """
        super().__init__(**kwargs)

        self.kernels = kernels.upper()
        self.separate_rt_kernels = separate_rt_kernels

        # Internal variables control behavior of spawned jobs. These should not
        # be set by the User, they are set by main processing functions here.
        self._force = None  # direction of input force for fwd/adj simulation
        self._cmpnt = None  # component of output synthetics/adjsrcs used

        # Internal lookup table for theta and theta_prime values which are 
        # used for waveform rotation. To be filled by setup()
        self._srcrcv_stats = None

    def check(self):
        """
        Additional checks for the Noise Inversion Workflow to ensure the
        required modules and parameters are set
        """
        super().check()

        assert("3D" in self._modules.solver.__class__.__name__), (
            f"Noise Inversion workflow requires solver module 'specfem3d' or " 
            f"'specfem3d_globe'"
        )

        assert(self._modules.solver.source_prefix == "FORCESOLUTION"), (
            f"Noise Inversion workflow requires solver `source_prefix` to be " 
            f"'FORCESOLUTION'"
        )

        assert(self._modules.preprocess.syn_data_format == "ASCII"), (
            f"Noise Inversion workflow requires solver `syn_data_format` to be " 
            f"'ASCII'"
        )

        acceptable_kernels = {"ZZ", "TT", "RR"}
        assert(set(self.kernels.split(",")).issubset(acceptable_kernels)), \
            f"`kernels` must be a subset of {acceptable_kernels}"

        # FORCESOLUTIONS required
        use_force_point_source = getpar(
            key="USE_FORCE_POINT_SOURCE", 
            file=os.path.join(self._modules.solver.path.specfem_data, 
                              "Par_file")
            )[1]   
        assert(use_force_point_source == ".true."), \
            "SPECFEM Par_file parameter `USE_FORCE_POINT_SOURCE` must be True"

    def setup(self):
        """Set up some required attributes for Noise Inversion"""
        super().setup()

        self._srcrcv_stats = get_src_rcv_lookup_table(
            path_to_data=self.solver.path.specfem_data,
            source_prefix=self.solver.source_prefix
        )

    @property
    def task_list(self):
        """
        USER-DEFINED TASK LIST. This property defines a list of class methods
        that take NO INPUT and have NO RETURN STATEMENTS. This defines your
        linear workflow, i.e., these tasks are to be run in order from start to
        finish to complete a workflow.

        This excludes 'check' (which is run during 'import_seisflows') and
        'setup' which should be run separately

        .. note::

            For workflows that require an iterative approach (e.g. inversion),
            this task list will be looped over, so ensure that any setup and
            teardown tasks (run once per workflow, not once per iteration) are
            not included.

        :rtype: list
        :return: list of methods to call in order during a workflow
        """
        return [self.evaluate_zz_misfit,
                self.run_zz_adjoint_simulations,
                self.evaluate_rt_misfit,
                self.run_rt_adjoint_simulations,
                self.sum_all_residuals,
                self.postprocess_event_kernels,
                self.evaluate_gradient_from_kernels,
                self.initialize_line_search,
                self.evaluate_line_search_misfit,
                self.update_line_search,
                self.finalize_iteration
                ]

    def trace_path(self, tag, comp=None):
        """
        Convenience path function that returns the full path for storing
        intermediate waveform files for a given component. 
        These generally adhere to how the `solver` module names directories. 
        
        Required because this workflow will do a lot of pre-rotation waveform 
        storage, so we use this function as the once-and-for-all definition for 
        the paths

        .. note ::

            Must be run by system.run() so that solvers are assigned individual
            task ids and working directories

        :type tag: str or None
        :param tag: sub directory tag, e.g., 'syn' to store synthetic waveforms 
            and 'adj' to store adjoint sources.
        :type comp: str or None
        :param comp: optional component used to tag the sub directory
        :rtype: str
        :return: full path to solver scratch traces directory to save waveforms
        """
        if comp is not None:
            tag = f"{tag}_{comp}".lower()
        return os.path.join(self.solver.cwd, "traces", tag)

    def evaluate_zz_misfit(self, **kwargs):
        """
        Run the forward solver to generate ZZ SGFs using a +Z component FORCE,
        and evalaute the misfit using the preprocessing module. Save the
        residual files but do not sum them.

        .. note::

            To rerun preprocessing only (e.g., you want to test out new window
            parameters), run the following commands:
            $ seisflows debug
            > workflow.setup()
            > workflow.evaluate_zz_misfit(_preproc_only=True)
        """
        # Skip if not valid
        if "ZZ" not in self.kernels:
            logger.info("ZZ not specified in parameter 'kernels'. Skipping")
            return 
        
        # Internal tracking parameters used to name sub-directories, save files
        self._force = "Z"
        self._cmpnt = "Z"

        # Residuals file looks like e.g., 'residuals_{src}_i01s00_ZZ.txt'
        save_residuals = os.path.join(
            self.path.eval_grad, "residuals", 
            f"residuals_{{src}}_{self.evaluation}_ZZ.txt"
            )
        super().evaluate_initial_misfit(save_residuals=save_residuals,
                                        sum_residuals=False, **kwargs
                                        )
        self._rename_preprocess_files(tag="ZZ")

    def run_zz_adjoint_simulations(self):
        """
        Run the adjoint solver to generate kernels for ZZ using the ZZ adjoint
        sources and applying the saved forward arrays from the ZZ forward
        simulation.
        """
        # Skip if not valid
        if "ZZ" not in self.kernels:
            logger.info("ZZ not specified in parameter 'kernels'. Skipping")
            return 

        # Internal tracking parameters used to name sub-directories, save files
        self._force = "Z"
        self._cmpnt = "Z"
        super().run_adjoint_simulations()

    def evaluate_rt_misfit(self, **kwargs):
        """
        Run the forward solver to generate E and N SGFs from E and N component
        FORCES. Preprocessing will wait until the N simulations have finished
        prior to rotating N and E SGF to RR and TT components. Preprocessing
        calculates misfit on the R and T components and then we rotate RR and TT
        adjoint sources into N and E components.

        .. warning::

            IMPORTANT: The order of simulations matters here! E must be first
        """
        # Skip if not valid
        if ("RR" not in self.kernels) and ("TT" not in self.kernels):
            logger.info("RR, TT not specified in parameter 'kernels'. Skipping")
            return 

        for force in ["E", "N"]:  # <- E before N required!
            self._force = force
            logger.info(msg.sub(f"MISFIT EVALUATION FORCE '{self._force}'"))
            # Residuals file e.g., 'residuals_{src}_i01s00_RT.txt'
            save_residuals = os.path.join(
                self.path.eval_grad, "residuals",
                f"residuals_{{src}}_{self.evaluation}_RT.txt"
                )
            # saves to `scratch/solver/{source_name}/E_FWD_ARR` or `N_FWD_ARR`
            # ! Make sure this matches naming convention in adjoint simulations
            save_forward_arrays = f"{self._force}_FWD_ARR"
            self.evaluate_initial_misfit(
                save_residuals=save_residuals, sum_residuals=False, 
                save_forward_arrays=save_forward_arrays, **kwargs
                )
        self._rename_preprocess_files(tag="RT")

    def run_rt_adjoint_simulations(self):
        """
        Run adjoint solver to generate horizontal kernels. Choice between
        separating kernels (ER, NR, ET, NT) requiring four adjoint simulations,
        or mixing kernels (ER + NR, ET + NT) requiring two adjoint simulations.
        See parameter `separate_rt_kernels` for choice.
        """
        # Skip if not valid
        if ("RR" not in self.kernels) and ("TT" not in self.kernels):
            logger.info("RR, TT not specified in parameter 'kernels'. Skipping")
            return 
        
        if self.separate_rt_kernels:
            self._run_rt_adjoint_simulations_separate()
        else:
            self._run_rt_adjoint_simulations_combined()

        # Unset internal tracking variables for safety
        self._force = None
        self._cmpnt = None

    def _run_rt_adjoint_simulations_separate(self):
        """
        Run adjoint solver for each kernel RR and TT (if requested) by running
        two adjoint simulations (E and N) per kernel with the appropriate
        saved E and N forward arrays.
        """
        # Four possible adjoint simulations: ER, NR, ET, NT
        for force in ["E", "N"]:
            # e.g., E_FWD_ARR (for E component force)
            load_forward_arrays = f"{force}_FWD_ARR"
            for cmpnt in ["R", "T"]:
                # Don't run a simulation if we don't need the kernels
                if cmpnt not in self.kernels:
                    continue

                # Intermediate state check to avoid rerunning all after failure
                _state_check = f"run_rt_adjoint_simulations_{force}{cmpnt}"
                if _state_check in self._states and \
                                        bool(self._states[_state_check]):
                    continue

                logger.info(
                    msg.sub(f"ADJOINT SIMULATION {force}{cmpnt}")
                    )

                # Assign internal variables used for bookkeeping
                self._force = force
                self._cmpnt = cmpnt

                # Fwd arrays will not be deleted until all simulations for a 
                # given FORCE are finished, that is, when we run the T adj sims
                self.run_adjoint_simulations(
                    load_forward_arrays=load_forward_arrays,
                    del_loaded_forward_arrays=bool(cmpnt == "T")  # last index
                )
                self._states[_state_check] = 1
                self.checkpoint()

    def _run_rt_adjoint_simulations_combined(self):
        """
        Run adjoint solver for each kernel RR and TT (if requested) by running
        one adjoint simulations (E and N) per kernel with the appropriate
        saved E and N forward arrays.
        """
        raise NotImplementedError

    def _rename_preprocess_files(self, tag):
        """
        Prevent preprocess module from overwriting its own log and figure files
        by simply renaming them with a tag.

        .. warning::

            This feels kludge-y, try to not have to do this by allowing misfit
            evaluation functions to set a tag on the figure/log naming
        """
        fids = glob(os.path.join(self.preprocess.path["_figures"],
                                 f"*{self.evaluation}.pdf"))
        unix.rename(f"{self.evaluation}.pdf",
                    f"{self.evaluation}_{tag}.pdf", fids)

        fids = glob(os.path.join(self.preprocess.path["_logs"],
                                 f"*{self.evaluation}.log"))
        unix.rename(f"{self.evaluation}.log",
                    f"{self.evaluation}_{tag}.log", fids)

    def sum_all_residuals(self):
        """
        Misfit files are tagged with the intended kernel they are generated
        for, which does not match the original `workflow.inversion` formatting.
        This function makes summation of residuals files more broad to encompass
        the updated file naming
        """
        # If we are the middle of a thrifty inversion, simply load the misfit
        # of the last accepted line search evaluation
        if self.thrifty and self._thrifty_status:
            total_misfit = self.optimize.load_vector(name="f_new")
            logger.info(f"total misfit `f_new` ({self.evaluation}) = "
                        f"{total_misfit:.2E}")
        # Else: sum all the misfit values from the ZZ, RR and TT misfit
        # evaluations (if accesible) together to create misfit value `f_new` for
        # current accepted model `m_new`
        else:
            residuals_files = glob(os.path.join(
                self.path.eval_grad, "residuals", 
                f"residuals_*_{self.evaluation}_??.txt")
            )
            self.sum_residuals(residuals_files, save_to="f_new")

    def prepare_data_for_solver(self, **kwargs):
        """
        Function Override of `workflow.forward.prepare_data_for_solver()` 
        run from within the `evaluate_initial_misfit` function

        Modifies the location of expected observed data, and removes any data
        previously stored within the `solver/traces/obs/` directory to avoid
        data conflict during workflow

        Data are searched for under the following locations:

            ZZ kernel: `path_data`/{source_name}/ZZ/*
            RR kernel: `path_data`/{source_name}/RR/*
            TT kernel: `path_data`/{source_name}/TT/*

        .. note ::

            Must be run by system.run() so that solvers are assigned individual
            task ids and working directories
        """
        # Define where the obs data is stored
        dst = self.trace_path("obs")

        # Since we need multiple preprocessing runs, we remove any existing data
        # that might have been set previously to avoid data conflicts/confusion,
        # otherwise the original function will skip trying to find data
        unix.rm(glob(os.path.join(dst, "*")))

        # Used for wildcard path naming to get R and T ('ZZ,RR,TT' -> 'RT')
        # Note that wildcard will be 'R', 'T', or 'RT'
        wildcard = "".join([_[0] for _ in self.kernels.split(",") if _ != "ZZ"])

        # Generating a wildcard string that will be used to copy in data
        dir_ = {"Z": "ZZ",
                "N": f"[{wildcard}][{wildcard}]",  # [RT][RT] -> both RR and TT
                "E": f"[{wildcard}][{wildcard}]"
                }[self._force]

        # Tell the original `Forward.prepare_data_for_solver` function where to
        # look for the required EGF data, which is assumed to be stored within
        # <PATH_DATA>/<SOURCE_NAME>/<RR_OR_TT>/*
        src = os.path.join(self.path.data, self.solver.source_name, dir_, "*")
        super().prepare_data_for_solver(_src=src)

    def evaluate_objective_function(self, save_residuals=False, components=None,
                                    **kwargs):
        """
        Function Override of `workflow.inversion.evaluate_objective_function`
        run from within the `evaluate_initial_misfit` function

        - ZZ kernel follows standard procedure as a normal inversion
        - RR and TT kernels require modification:
            - N/E synthetics rotated -> R/T, to match EGF data
            - Objective function evaluated for R/T, R/T adj. srcs generated
            - R/T adjoint sources rotated back -> N/E for adjoint simulations

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type save_residuals: str
        :param save_residuals: if not None, path to write misfit/residuls to
        :type components: list
        :param components: optional list of components to ignore preprocessing
            traces that do not have matching components. The adjoint sources for
            these components will be 0. E.g., ['Z', 'N']. If None, all available
            components will be considered.
        """
        # Z component force behaves like a normal workflow, except that we only
        # create adjoint sources for the Z component (E, N will be 0's)
        if self._force == "Z":
            super().evaluate_objective_function(save_residuals=save_residuals,
                                                components=["Z"])
        # Run E and N misfit quantification
        else:
            # ==================================================================
            # IMPORTANT: The order of simulations matters here! E must be first
            # ==================================================================
            if self._force == "E":
                logger.info("waiting for 'N' forward simulation for processing")
                return

            # This will generate RR and TT synthetics in `traces/syn` with
            # synthetics generated using `traces/syn_e` and `traces/syn_n`
            self.rotate_ne_traces_to_rt()

            # Run preprocessing with rotated synthetics for horizontal cmpnts,
            # generate adjoint sources for R and T components
            super().evaluate_objective_function(save_residuals=save_residuals,
                                                components=["T", "R"]
                                                )

            # Re-rotate T and R adjoint sources to N and E components for 
            # adjoint simulations. Only rotate what is required for adj sim.
            for choice in ["T", "R"]:
                if choice in self.kernels:
                    self.rotate_rt_adjsrcs_to_ne(choice=choice)

    def rotate_ne_traces_to_rt(self, tag="syn"):
        """
        Parallelized rotation function to get N and E component synthetic
        waveforms, generated by N and E forcesolution simulations, into
        R and T component synthetics, generated by R and T force sources.

        See Reference 1 in top docstring for detailed explanation. General idea
        is that you cannot have a radial or transverse source for N>1 stations
        with only one simulation, so instead we run N and E force simulations,
        and then rotate the orthogonal N and E component synthetics to get
        RR and TT Synthetic Greens Functions.

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type tag: str
        :param tag: where to look for waveform data within the scratch dir.
            Example path is: scratch/solver/<source_name>/traces/<tag>_?/*
            Tag by default is 'syn' but can also be 'obs' for generating
            synthetic data
        """
        logger.info("rotating N and E synthetics to RR and TT components")

        # Gather waveform files from previous simulations and sort so that they
        # are technically in the same order. Assuming directory structure here.
        # Naming convention: AB (A=force source direction, B=waveform component)
        fids_ee = sorted(glob(os.path.join(self.trace_path(tag=tag, comp="e"),
                                           self.solver.data_wildcard(comp="E")))
                         )
        fids_ne = sorted(glob(os.path.join(self.trace_path(tag=tag, comp="n"),
                                           self.solver.data_wildcard(comp="E")))
                         )
        fids_en = sorted(glob(os.path.join(self.trace_path(tag=tag, comp="e"),
                                           self.solver.data_wildcard(comp="N")))
                         )
        fids_nn = sorted(glob(os.path.join(self.trace_path(tag=tag, comp="n"),
                                           self.solver.data_wildcard(comp="N")))
                         )

        # Double check that we have found files, and that they match
        assert(len(fids_ee) != 0), f"No synthetic traces found for rotation"
        assert (len(fids_ee) == len(fids_ne) == len(fids_en) == len(fids_nn)), \
            f"number of synthetic waveforms does not match for all components"

        # Rotate NE synthetics to RT synthetics, in parallel
        with ProcessPoolExecutor(max_workers=unix.nproc()) as executor:
            futures = [
                executor.submit(self._rotate_ne_trace_to_rt_single,
                                f_ee, f_ne, f_en, f_nn)
                for f_ee, f_ne, f_en, f_nn in zip(fids_ee, fids_ne,
                                                  fids_en, fids_nn)
                ]
        # Simply wait until this task is completed because its just file writing
        wait(futures)

    def _rotate_ne_trace_to_rt_single(self, f_ee, f_ne, f_en, f_nn):
        """
        Parallalizable private function to rotate NE synthetics to RR and TT

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type f_ee: str
        :param f_ee: path to the EE synthetic waveform (E force, E component)
        :type f_ne: str
        :param f_ne: path to the NE synthetic waveform (N force, E component)
        :type f_en: str
        :param f_en: path to the EN synthetic waveform (E force, N component)
        :type f_nn: str
        :param f_nn: path to the NN synthetic waveform (N force, N component)
        """
        src_name = self.solver.source_name

        # Figure out station and file naming from the parts of the file ID
        # !!! Assuming SPECFEM3D file naming structure here
        net, sta, cha, *ext = os.path.basename(f_nn).split(".")
        ext = ".".join(ext)  # e.g., SEM3DGLOBE ['sem', 'ascii'] -> sem.ascii
        rcv_name = f"{net}_{sta}"

        # Get azimuth angles from lookup table for the given src-rcv pair
        theta = self._srcrcv_stats[src_name][rcv_name].theta
        theta_p = self._srcrcv_stats[src_name][rcv_name].theta_p

        # Read in the N/E synthetic waveforms that need to be rotated
        # !!! Assuming that each Stream only has one Trace in it
        tr_ee = read(f_ee, data_format=self.solver.syn_data_format)[0]
        tr_ne = read(f_ne, data_format=self.solver.syn_data_format)[0]
        tr_en = read(f_en, data_format=self.solver.syn_data_format)[0]
        tr_nn = read(f_nn, data_format=self.solver.syn_data_format)[0]

        # Rotate to get RR and TT synthetics; Wang et al. (2019) Eq. 9/10
        tr_rr, tr_tt = rotate_ne_trace_to_rt(tr_ee=tr_ee, tr_ne=tr_ne,
                                             tr_en=tr_en, tr_nn=tr_nn,
                                             theta=theta, theta_p=theta_p
                                             )

        # Write TT/RR synthetics back to the main synthetic trace directory
        # !!! Assuming SPECFEM adjoint source file name structure
        if "TT" in self.kernels:
            # scratch/solver/{source_name}/traces/syn/NN.SSS.?XT.sem?*
            fid_t = os.path.join(self.solver.cwd, "traces", "syn",
                                 f"{net}.{sta}.{cha[:2]}T.{ext}")
            write(st=Stream(tr_tt), fid=fid_t,
                  data_format=self.solver.syn_data_format)
        if "RR" in self.kernels:
            # scratch/solver/{source_name}/traces/syn/NN.SSS.?XR.sem?*
            fid_r = os.path.join(self.solver.cwd, "traces", "syn",
                                 f"{net}.{sta}.{cha[:2]}R.{ext}")
            write(st=Stream(tr_rr), fid=fid_r,
                  data_format=self.solver.syn_data_format)

    def rotate_rt_adjsrcs_to_ne(self, choice):
        """
        Rotates R and T adjoint sources generated by the preprocessing module
        back to N and E component synthetics. See `rotate_ne_traces_to_rt` and
        Ref. 1 for explanations on why this is necessary.

        Four potential sets of adjoint sources generated during workflow:
        - ER: RR synthetics that have been rotated so that they appear to
            originate from an E component force source.
        - ET: TT synthetics that have been rotated so that they appear to
            originate from an E component force source
        - NR: RR synthetics that have been rotated so that they appear to
            originate from an N component force source
        - NT: TT synthetics that have been rotated so that they appear to
            originate from an N component force source

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type choice: str
        :param choice: define the input component, 'R' or 'T' for the incoming
            adjoint source as rotation matrix will be different for both.
        """
        assert(choice in ["R", "T"]), f"`choice` must be in 'R', 'T'"

        # Find all available adjoint sourcse for a given choice R or T
        # !!! Hard code the file naming scheme of SPECFEM adjoint sources
        _fid_wc = os.path.join(self.trace_path(tag="adj"), f"*.?X{choice}.adj")
        fids = sorted(glob(_fid_wc))

        # Check that we actually have data, otherwise what's the point?
        assert fids, f"no adjoint sources found for path: {_fid_wc}"
        logger.info(f"rotating {len(fids)} {choice} component adjoint sources")

        # Generate holding directories for rotated adjoint sources which will
        # be queried during each adjoint simulation
        for comp in [f"e{choice.lower()}", f"n{choice.lower()}"]:
            if not os.path.exists(self.trace_path(tag="adj", comp=comp)):
                # e.g., path/to/traces/adj_et
                unix.mkdir(self.trace_path(tag="adj", comp=comp))

        # Rotate NE streams to RT in parallel
        with ProcessPoolExecutor(max_workers=unix.nproc()) as executor:
            futures = [
                executor.submit(self._rotate_rt_adjsrc_to_ne_single,
                                fid, choice) for fid in fids
                ]
        # Simply wait until this task is completed with file writing
        wait(futures)

    def _rotate_rt_adjsrc_to_ne_single(self, fid, choice=None):
        """
        Parallellizable function to rotate R or T adjoint sources to N and E
        component synthetics for use in adjoint simulations.

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type fid: str
        :param fid: path to the RR or TT adjoint source that will be read in and
            rotated into four separate adjoint sources
        :type choice: str
        :param choice: define the input component, 'R' or 'T' for the incoming
            adjoint source as rotation matrix will be different for both.
        """
        src_name = self.solver.source_name

        # Define pertinent information about files and output names
        net, sta, cha, *ext = os.path.basename(fid).split(".")
        _comp = cha[-1].lower()
        if choice is None:
            choice = _comp  # R or T, used for file naming
        ext = ".".join(ext)  # ['semd', 'ascii'] -> 'semd.ascii.'
        rcv_name = f"{net}_{sta}"

        # Collect azimuth angles from lookup table computed in preprocess setup
        theta = self._srcrcv_stats[src_name][rcv_name].theta
        theta_p = self._srcrcv_stats[src_name][rcv_name].theta_p

        # Read in the R or T adjoint source that needs to be rotated. Double
        # check that everyone agrees on the choice of R or T
        tr = read(fid, data_format=self.preprocess.syn_data_format)[0]
        assert(choice == tr.stats.component), \
            f"`choice` {choice} mismatch trace component {tr.stats.component}"

        # Rotate the given adjoint source to get four adjoint sources which
        # are required for the N and E component adjoint simulations
        # Follows Wang et al. (2019) Eqs. 16, 18
        tr_ee, tr_ne, tr_en, tr_nn = rotate_rt_adjsrc_to_ne(tr=tr,
                                                            theta=theta,
                                                            theta_p=theta_p)

        # Write out four adjoint sources, one for each force + component combo,
        # write out the adjoint source in the correct sub-directory to determine
        # if it came from a TT or RR adjoint source
        write_dict = {"ee": tr_ee, "ne": tr_ne, "en": tr_en, "nn": tr_nn}

        for force in ["e", "n"]:
            for comp in ["e", "n"]:
                # e.g., traces/adj_er/NN.SSS.CCN.*
                fid = os.path.join(
                    self.trace_path(tag="adj", comp=f"{force}{choice.lower()}"),
                    f"{net}.{sta}.{cha[:2]}{comp.upper()}.{ext}"
                )
                tr = write_dict[f"{force}{comp}"]
                write(st=Stream(tr), fid=fid,
                      data_format=self.preprocess.syn_data_format
                      )

    def run_forward_simulations(self, path_model, save_traces=False,
                                export_traces=False,
                                **kwargs):
        """
        Function Override of `workflow.forward.run_forward_simulation` 

        - Edits FORCESOLUTION file to set the correct force direction (E, N, Z)
        - Redirect trace saving/export for more refined tagging based on force

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type path_model: str
        :param path_model: path to SPECFEM model files used to run the forwarsd
            simulations. Files will be copied to each individual solver
            directory.
        :type save_traces: str
        :param save_traces: full path location to save synthetic traces after
            successful completion of forward simulations. By default, they are
            stored in 'scratch/solver/<SOURCE_NAME>/traces/syn'. Overriding
            classes may re-direct synthetics by setting this variable
        :type export_traces: str
        :param export_traces: full path location to export (copy) synthetic
            traces after successful completion of forward simulations. Each fwd
            simulation erases the synthetics of the previous forward simulation,
            so exporting to disk is important if the User wants to save
            waveform data. Set parameter `export_traces` True in the parameter
            file to access this option. Overriding classes may re-direct
            synthetics by setting this variable.
        :raises AssertionError: if internal variable `_force` is not set by
            the calling function
        """
        # Internal variable check to make sure class variable properly set
        assert(self._force is not None), (
            f"`run_forward_simulation` requires that the internal attribute " 
            f"`_force` is set prior to running forward simulations"
        )

        # Edit the force vector based on the internal value for chosen kernel
        # !!! SPECFEM3D(_Globe) specific force file formatting
        kernel_vals = None
        if self._force == "Z":
            kernel_vals = ["0.d0", "0.d0", "1.d0"]  # format: [E, N, Z]
            # ZZ SGFs are just saved straight to the 'syn' directory
            save_traces = save_traces or self.trace_path(tag="syn")
        else:
            if self._force == "E":
                kernel_vals = ["1.d0", "0.d0", "0.d0"]  # format: [E, N, Z]
            elif self._force == "N":
                kernel_vals = ["0.d0", "1.d0", "0.d0"]  # format: [E, N, Z]

            # e.g., solver/{source_name}/traces/syn_e
            save_traces = save_traces or \
                    self.trace_path(tag="syn", comp=self._force)

        # Clear out synthetics from previous evaluations to avoid file conflict
        unix.rm(os.path.join(save_traces, "*"))
        unix.mkdir(save_traces)

        # Set FORCESOLUTION (3D/3D_GLOBE) to ensure correct force for kernel
        # Assuming we have 'cd'd into the current working directory
        self.solver.set_parameters(keys=["component dir vect source E",
                                         "component dir vect source N",
                                         "component dir vect source Z_UP"],
                                   vals=kernel_vals, file="DATA/FORCESOLUTION",
                                   delim=":", comment="!")

        # Exporting traces to disk for permanent saving. Ensure that the force
        # tag is set so that subsequent trace exports don't overwrite existing
        # If parameter `export_traces` is set False, this will be ignored
        if export_traces is None:
            # e.g., output/i01s00/{source}/syn_Z/*
            export_traces = os.path.join(
                self.path.output, "solver", self.evaluation,
                self.solver.source_name, f"syn_{self._force}"
            )

        super().run_forward_simulations(path_model, save_traces=save_traces,
                                        export_traces=export_traces, 
                                        **kwargs
                                        )

    def _run_adjoint_simulation_single(self, save_kernels=None, 
                                       export_kernels=None, **kwargs):
        """
        Function Override of `workflow.migration._run_adjoint_simulation_single`

        1) Creates necessary empty adjoint sources, e.g., ZZ kernel only 
           requires 'Z' component adjoint sources, and 'N' and 'E' MUST be 0
        2) For N and E (TT and RR kernels) adjoint simulations, symlinks collect
           adjoint sources to be discoverable by SPECFEM. Note that for 
           horizontal components, four sets of adjoint sources are available.

        .. note::

            Must be run by system.run() so that solvers are assigned
            individual task ids/working directories.

        .. note:: 

            see solver.specfem.adjoint_simulation() for full 
            detailed list of input parameters

        :type save_kernels: str
        :param save_kernels: path to a directory where kernels created by the 
            adjoint simulation are moved to for further use in the workflow
            Defaults to saving kernels in `scratch/eval_grad/kernels/<source>`
        :type export kernels: str
        :param export_kernels: path to a directory where kernels are copied for
            more permanent storage, where they will not be wiped by `clean` or
            `restart`. User parameter `export_kernels` must be set `True`.
        """
        # Internal variable check
        assert(self._force is not None), (
            f"`run_adjoint_simulations` requires that the internal attribute " 
            f"`_force` is set prior to running forward simulations"
        )
        assert(self._cmpnt is not None), (
            f"`run_adjoint_simulations` requires that the internal attribute " 
            f"`_cmpnt` is set prior to running forward simulations"
        )
        # Kernel subdirectory should be one of: ZZ, NT, ET, NR, ER
        subdir = f"{self._force}{self._cmpnt}"

        # Redirect paths to where we save and export kernels to avoid overwrites
        if save_kernels is None:
            save_kernels = os.path.join(self.path.eval_grad, "kernels",
                                        self.solver.source_name, subdir)
        if export_kernels is None and self.export_kernels:
            export_kernels = os.path.join(self.path.output, "kernels",
                                          self.solver.source_name, subdir)
        else:
            export_kernels = False

        # Run adjoint simulations for each kernel
        if self._force == "Z":
            self._generate_empty_adjsrcs(components=["E", "N"])
            
            super()._run_adjoint_simulation_single(save_kernels, export_kernels,
                                                   **kwargs)
        elif self._force in ["E", "N"]:
            # Remove any existing adjoint sources from directory 
            unix.rm(self.trace_path(tag="adj"))
            unix.mkdir(self.trace_path(tag="adj"))

            # Generate empty Z components because we only have E and N component
            self._generate_empty_adjsrcs(components=["Z"])

            # Symlink the correct set of adjoint sources to the 'adj' directory
            # `adj_dir` is something like 'adj_nt'
            adj_dir = self.trace_path(
                tag="adj", comp=f"{self._force.lower()}{self._cmpnt.lower()}"
            )
            for src in glob(os.path.join(adj_dir, "*")):
                unix.ln(src, self.trace_path("adj"))

            super()._run_adjoint_simulation_single(save_kernels, export_kernels,
                                                   **kwargs)

    def _generate_empty_adjsrcs(self, components):
        """
        Internal NoiseInversion function used to generate empty (zero amplitude) 
        adjoint sources for every station and given `component`. Uses the Solver 
        and Preprocess modules to get after file naming and trace 
        characteristics.

        This function is required because the original Inversion method for 
        generating empty adjoint sources is insuffficient for the file structure
        that gets craeted here

        .. warning::

            !!! This entire function makes assumptions about file naming
            structure for SPECFEM generated synthetics that may be too rigid/
            hardcoded.

        .. note::

            Must be run by system.run() so that solvers are assigned
            individual task ids/working directories.

        :type components: list of str
        :param components: components to generate empty adjoint sources for.
            e.g., ['E', 'N'] will generate E and N component adjoint sources.
            Note that any files matching the output adjoint source file name
            will be removed so ensure that there is no actual adjoint source
            data in this file.
        """
        # Grab a dummy synthetic trace to use for time series structure
        st = read(fid=self.solver.data_filenames("syn")[0],
                  data_format=self.solver.syn_data_format)
        st[0].data *= 0  # zero out the amplitude for empty adjoint source

        # Get list of synthetic traces which require a corresponding adj source
        # and rename them so that they follow the expected SPECFEM format
        adj_fids = [rename_as_adjoint_source(fid=os.path.basename(f),
                                             fmt=self.solver.syn_data_format)
                    for f in self.solver.data_filenames("syn")
                    ]

        for fid in adj_fids:
            # !!! Making assumptions about the filenaming structure here
            channel = fid.split(".")[2]  # NN.SSS.CCc.adj
            # Write out adjoint sources for all requested components
            for component in components:
                channel_out = channel[:2] + component  # e.g., MXZ -> MXR
                # !!! May be an issue if station name is the same as channel
                fid_out = fid.replace(channel, channel_out)
                adjpath = os.path.join(self.trace_path("adj"), fid_out)
                # Do not overwrite existing adjoint sources
                if not os.path.exists(adjpath):
                    write(st=st, fid=adjpath,
                          data_format=self.preprocess.syn_data_format
                          )

    def postprocess_event_kernels(self):
        """
        Function Override of `workflow.migration.postprocess_event_kernels`

        - Combines multiple individual kernels, K, for each source.
        - `K_event = K_ZZ + K_TT + K_RR`, where (K_TT = K_ET + K_NT and
            K_RR = K_ER + K_NR).
        - Uses the original function machinery to do the final kernel summation,
            K_misfit = sum(K_event) and postprocessing (smooth, mask, etc.)

        .. warning::

            Assumes the subdirectory structure of kernels for path `eval_grad`
        """
        # If only ZZ kernels, then we don't need to do any prior kernel summing.
        # Simply reorganize directory structures so that the original function
        # can find the required files
        if self.kernels == "ZZ":
            # $ mv kernels/src/ZZ/* -> kernels/src
            for srcname in self.solver.source_names:
                dst = os.path.join(self.path.eval_grad, "kernels", srcname)
                src = glob(os.path.join(dst, "ZZ", "*"))

                unix.mv(src=src, dst=dst)

            super().postprocess_event_kernels()

            # Return to avoid accessing code below which is only required if any
            # horizontal components are involved
            return

        # RR and TT kernels require running SPECFEM executable `xcombine_sem`
        # so we need to define a function which can be fed to 'system.run()'
        def generate_event_kernels(**kwargs):
            """
            Combine horizontal (TT=ET+NT; RR=ER+NR) kernels and then sum
            all individual kernel contributions (K=ZZ+RR+TT) to generate the
            final event kernel for each source.

            .. note::

                Must be run by system.run(single=True) so that the operation
                has access to one compute node for the kernel combination
            """
            # Parameters are constant and static for this whole process
            parameters = [f"{par}_kernel" for par in self.solver._parameters] 

            # We need to combine the N? and E? kernels for each source by itself
            for src in self.solver.source_names:
                # Subdirectory containing kernels for a given source
                # !!! Assuming the dir. structure defined by postprocess module
                src_path = os.path.join(self.path.eval_grad, "kernels", src)

                # This will bring in all available kernels from: ER, NR, ET, NT
                input_paths = []
                if "RR" in self.kernels:
                    input_paths.append(os.path.join(src_path, "ER"))
                    input_paths.append(os.path.join(src_path, "NR"))
                if "TT" in self.kernels:
                    input_paths.append(os.path.join(src_path, "ET"))
                    input_paths.append(os.path.join(src_path, "NT"))
                if "ZZ" in self.kernels:
                    input_paths.append(os.path.join(src_path, "ZZ"))

                # We save the summed event kernel directly into the source
                # subdirectory to match the expected input of the original fx.
                output_path = os.path.join(self.path.eval_grad, "kernels", src)

                # Calling SPECFEM binaries to do the actual kernel summation
                self.solver.combine(input_paths, output_path, parameters)
        
        # Run above function on system using a single compute node
        # NOTE: May need to increase the tasktime by a factor of 2 because 
        # there are many more kernel manipulations that need to happen and this 
        # task usually fails due to timeout when `tasktime` is set for an 
        # adjoint simulation (tasktime=self.system.tasktime * 2)
        self.system.run([generate_event_kernels], single=True, 
                        tasktime=self.system.tasktime * 1)

        # Now the original function takes over and combines event kernels into
        # a misfit kernel, and applies smoothing, masking, etc.
        super().postprocess_event_kernels()

    def evaluate_line_search_misfit(self):
        """
        Function Overwrite of `workflow.inversion._evaluate_line_search_misfit`
        Called inside `workflow.inversion.perform_line_search`.

        Alters the original function by allowing for multiple forward
        simulations required for both vertical and horizontal SGF creation.

        .. warning::

            Each call of this function will save residuals but these will be 
            ignored and the final residual file will only be created once all 
            forward simulations are run
        """
        logger.info(msg.sub(f"LINE SEARCH STEP COUNT "
                            f"{self.optimize.step_count:0>2}"))

        logger.info(f"`m_try` model parameters for line search evaluation:")
        self.solver.check_model_values(path=os.path.join(self.path.eval_func,
                                                         "model"))

        # Determine which forward simulations we will need to run
        cfg = {}
        if "ZZ" in self.kernels:
            cfg["Z"] = {"tag": "ZZ", "components": ["Z"]}
        if ("RR" in self.kernels) or ("TT" in self.kernels):
            # E before N is required
            cfg["E"] = {"tag": "RT", "components": ["T", "R"]}
            cfg["N"] = {"tag": "RT", "components": ["T", "R"]}

        # Run forward simulations and misfit calculation for each required force
        for force, attrs in cfg.items():
            tag = attrs["tag"]
            components = attrs["components"]
            _state_check = f"evaluate_line_search_misfit_{force}"
            self._force = force

            # Intermediate state check to see if we already ran this force
            if _state_check in self._states and \
                bool(self._states[_state_check]):
                continue

            logger.info(msg.sub(f"MISFIT EVALUATION FOR FORCE '{self._force}'"))
            self.system.run(
                [self.prepare_data_for_solver,
                 self.run_forward_simulations,
                 self.evaluate_objective_function
                 ],
                path_model=os.path.join(self.path.eval_func, "model"),
                save_residuals=os.path.join(
                    self.path.eval_func, "residuals",
                    f"residuals_{{src}}_{self.evaluation}_{tag}.txt"),
                components=components
            )
            self._rename_preprocess_files(tag)
            self._states[_state_check] = 1
            self.checkpoint()
       
        # Sum the misfit from all forward simulations and all kernels
        residuals_files = glob(
            os.path.join(self.path.eval_func, "residuals", 
                         f"residuals_*_{self.evaluation}_*.txt")
        )
        self.sum_residuals(residuals_files, save_to="f_try")

        # Reset states incase we need to run again
        for force in cfg.keys():
            self._states[f"evaluate_line_search_misfit_{force}"] = 0


